{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas            as pd\n",
    "import plotly.express    as px\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy             as np\n",
    "import sklearn           as sk\n",
    "import seaborn           as sns\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk import NaiveBayesClassifier\n",
    "from nltk.corpus    import stopwords\n",
    "from nltk.classify  import accuracy \n",
    "from sklearn.tree                    import DecisionTreeClassifier\n",
    "from sklearn.metrics                 import accuracy_score\n",
    "from sklearn.datasets                import fetch_openml\n",
    "from sklearn.ensemble                import RandomForestClassifier\n",
    "from sklearn.neighbors               import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.naive_bayes             import MultinomialNB\n",
    "from sklearn.neural_network          import MLPClassifier\n",
    "from sklearn.model_selection         import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Giovanni Janzante Gianini\n",
    "\n",
    "### RM 95306\n",
    "### 2TDCR\n",
    "\n",
    "\n",
    "#### Necessidade 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv', encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando uma coluna de numeros dependendo da linguagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linguagem(linha):\n",
    "\n",
    "    if linha['language']=='English':\n",
    "        return 1\n",
    "    elif linha['language']=='Spanish':\n",
    "        return 2\n",
    "    elif linha['language']=='Portuguese':\n",
    "        return 3\n",
    "    elif linha['language']=='Italian':\n",
    "        return 4\n",
    "    elif linha['language']=='French':\n",
    "        return 5\n",
    "    elif linha['language']=='Chinese':\n",
    "        return 6\n",
    "    else:\n",
    "        return 7\n",
    "\n",
    "def tamanho_mensagem(linha):\n",
    "    return len(linha['text'])\n",
    "\n",
    "df['language(num)'] = df.apply(linguagem, axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removendo STOPWORDS de todos os textos em todas as linguas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def processa_mensagem(linha):\n",
    "    msg = linha[\"text\"]\n",
    "    msg = msg.lower()\n",
    "    stops = set(stopwords.words(\"english\") + stopwords.words(\"portuguese\") + stopwords.words(\"spanish\") + stopwords.words(\"chinese\") + stopwords.words(\"italian\") + stopwords.words(\"french\"))\n",
    "    \n",
    "    # Vamos separar só as palavras que não são stopwords (e jogar fora o resto)\n",
    "    palavras_filtradas = []\n",
    "    for palavra in msg.split(' '):\n",
    "        if palavra not in stops: # a palavra não é uma stopword\n",
    "            palavras_filtradas.append(palavra)\n",
    "            \n",
    "    msg_sem_stopwords = ' '\n",
    "    for palavra in palavras_filtradas:\n",
    "        msg_sem_stopwords = msg_sem_stopwords + ' ' + palavra\n",
    "    \n",
    "    msg_sem_stopwords = \" \".join([palavra for palavra in msg.split(\" \")\n",
    "                                  if palavra not in stops])\n",
    "    \n",
    "    return msg_sem_stopwords\n",
    "\n",
    "df[\"text\"] = df.apply(processa_mensagem, axis=1)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando variaveis e treinando o modelo para predizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X ,y = df['text'] ,df['language(num)']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "vect = CountVectorizer() # não usamos os dados de teste nele!\n",
    "vect.fit(X_train)\n",
    "\n",
    "print(vect.get_feature_names_out()[1500:1510])\n",
    "X_train = vect.transform(X_train)\n",
    "X_test  = vect.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo o metodo para predizer o modelo de linguagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando a Acurácia de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(X_pred, y_test)\n",
    "print(f\"Acurácia: {round(acc, 4)*100}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando a Acurácia do modelo de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred_train = clf.predict(X_train)\n",
    "acc_train = accuracy_score(X_pred_train, y_train)\n",
    "print(f\"Acurácia: {round(acc_train, 4)*100}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizar teste de frases com o nosso modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mensagem_teste = \"aujourd'hui je me suis réveillé le matin\"\n",
    "resposta = clf.predict(vect.transform([mensagem_teste]))\n",
    "resposta = resposta[0]\n",
    "\n",
    "if resposta == 1:\n",
    "     res = \"English\"\n",
    "elif resposta == 2:\n",
    "     res = \"Spanish\"\n",
    "elif resposta == 3:\n",
    "     res = \"Portuguese\"\n",
    "elif resposta == 4:\n",
    "     res = \"Italian\"\n",
    "elif resposta == 5:\n",
    "     res = \"French\"\n",
    "elif resposta == 6:\n",
    "     res = \"Chinese\"\n",
    "else:\n",
    "     print(\"Erro\")\n",
    "print(res)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
